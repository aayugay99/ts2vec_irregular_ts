name: ts2vec_churn_dyn_pool

path: data/preprocessed_new/churn.parquet

split:
  random_state: 42
  val_size: 0.1
  test_size: 0.1

dataset:
  _target_: datasets.TS2VecDataset
  min_seq_len: 15

preprocessor:
  _target_: ptls.preprocessing.PandasDataPreprocessor
  col_id: user_id
  col_event_time:
    _target_: utils.preprocessing.CustomDatetimeNormalization
    col_name_original: timestamp
    col_name_target: event_time
    min_timestamp: 1475798400
  cols_category: [mcc_code]
  cols_first_item: [global_target]

datamodule:
  _target_: ptls.frames.PtlsDataModule
  train_batch_size: 48
  valid_batch_size: 48
  train_num_workers: 16
  valid_num_workers: 16

model:
  _target_: modules.TS2VecDynamicPool
  loss: 
    _target_: losses.DynamicPoolLoss
  optimizer_partial:
    _partial_: True
    _target_: torch.optim.Adam
    lr: 0.004
  lr_scheduler_partial: 
    _partial_: True
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    factor: .9025
    patience: 5
    mode: min
  seq_encoder: 
    _target_: nn.seq_encoder.ConvSeqEncoder
    trx_encoder: 
      _target_: ptls.nn.TrxEncoder
      use_batch_norm_with_lens: True
      norm_embeddings: False
      embeddings_noise: 0.003
      embeddings: {mcc_code: {in: 345, out: 24}}
      numeric_values: {amount: identity}
    hidden_size: 1024
    num_layers: 10
    dropout: 0.1

checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  monitor: valid_loss
  mode: min

early_stopping: null

logger: null

trainer:
  _target_: pytorch_lightning.trainer.Trainer
  max_epochs: 50
  devices: [0]
  accelerator: gpu

n_runs: 5