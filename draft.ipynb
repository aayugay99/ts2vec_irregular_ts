{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.data_load.datasets.memory_dataset import MemoryMapDataset\n",
    "\n",
    "from ptls.nn import TrxEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/preprocessed_new/churn.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>mcc_code</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>global_target</th>\n",
       "      <th>holiday_target</th>\n",
       "      <th>weekend_target</th>\n",
       "      <th>churn_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-10-21 00:00:00</td>\n",
       "      <td>5023.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-10-12 12:24:07</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-12-05 00:00:00</td>\n",
       "      <td>767.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-21 00:00:00</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-10-24 13:14:24</td>\n",
       "      <td>36562.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490508</th>\n",
       "      <td>10215</td>\n",
       "      <td>37</td>\n",
       "      <td>2016-12-17 00:00:00</td>\n",
       "      <td>2110.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490509</th>\n",
       "      <td>10215</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-12-16 00:00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490510</th>\n",
       "      <td>10215</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-12-06 00:00:00</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490511</th>\n",
       "      <td>10215</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-06 13:39:49</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490512</th>\n",
       "      <td>10215</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-06 13:42:19</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490513 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  mcc_code           timestamp   amount  global_target  \\\n",
       "0             0        19 2017-10-21 00:00:00   5023.0              0   \n",
       "1             0         2 2017-10-12 12:24:07  20000.0              0   \n",
       "2             0        10 2017-12-05 00:00:00    767.0              0   \n",
       "3             0         1 2017-10-21 00:00:00   2031.0              0   \n",
       "4             0         9 2017-10-24 13:14:24  36562.0              0   \n",
       "...         ...       ...                 ...      ...            ...   \n",
       "490508    10215        37 2016-12-17 00:00:00   2110.9              0   \n",
       "490509    10215         1 2016-12-16 00:00:00     31.0              0   \n",
       "490510    10215         1 2016-12-06 00:00:00    182.0              0   \n",
       "490511    10215         2 2016-12-06 13:39:49   5000.0              0   \n",
       "490512    10215         2 2016-12-06 13:42:19  30000.0              0   \n",
       "\n",
       "        holiday_target  weekend_target  churn_target  \n",
       "0                    0               1             0  \n",
       "1                    0               0             0  \n",
       "2                    0               0             0  \n",
       "3                    0               1             0  \n",
       "4                    0               0             0  \n",
       "...                ...             ...           ...  \n",
       "490508               0               1             0  \n",
       "490509               0               0             0  \n",
       "490510               0               0             0  \n",
       "490511               0               0             0  \n",
       "490512               0               0             0  \n",
       "\n",
       "[490513 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = PandasDataPreprocessor(\n",
    "    col_id=\"user_id\",\n",
    "    col_event_time=\"timestamp\",\n",
    "    event_time_transformation=\"dt_to_timestamp\",\n",
    "    cols_category=[\"mcc_code\"],\n",
    "    cols_numerical=[\"amount\"],\n",
    "    cols_first_item=\"global_target\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preproc.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MemoryMapDataset(data, [SeqLenFilter(15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_encoder = TrxEncoder(\n",
    "    embeddings={\n",
    "        \"mcc_code\": {\"in\": 345, \"out\": 24}\n",
    "    },\n",
    "    numeric_values={\n",
    "        \"amount\": \"identity\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "# from models.dilated_conv import DilatedConvEncoder\n",
    "from nn.seq_encoder.dilated_conv import DilatedConvEncoder\n",
    "from ptls.data_load import PaddedBatch\n",
    "\n",
    "def generate_continuous_mask(B, T, n=5, l=0.1):\n",
    "    res = torch.full((B, T), True, dtype=torch.bool)\n",
    "    if isinstance(n, float):\n",
    "        n = int(n * T)\n",
    "    n = max(min(n, T // 2), 1)\n",
    "    \n",
    "    if isinstance(l, float):\n",
    "        l = int(l * T)\n",
    "    l = max(l, 1)\n",
    "    \n",
    "    for i in range(B):\n",
    "        for _ in range(n):\n",
    "            t = np.random.randint(T-l+1)\n",
    "            res[i, t:t+l] = False\n",
    "    return res\n",
    "\n",
    "def generate_binomial_mask(B, T, p=0.5):\n",
    "    return torch.from_numpy(np.random.binomial(1, p, size=(B, T))).to(torch.bool)\n",
    "\n",
    "class TSEncoder(nn.Module):\n",
    "    def __init__(self, trx_encoder, output_dims, depth=10, mask_mode='binomial'):\n",
    "        super().__init__()\n",
    "        self.trx_encoder = trx_encoder\n",
    "        self.output_dims = output_dims\n",
    "        self.hidden_dims = trx_encoder.output_size\n",
    "        self.mask_mode = mask_mode\n",
    "        # self.input_fc = nn.Linear(input_dims, hidden_dims)\n",
    "        self.feature_extractor = DilatedConvEncoder(\n",
    "            self.hidden_dims,\n",
    "            [self.hidden_dims] * depth + [output_dims],\n",
    "            kernel_size=3\n",
    "        )\n",
    "        self.repr_dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "    def forward(self, x, mask=None):  # x: B x T x input_dims\n",
    "        if mask is None:\n",
    "            if self.training:\n",
    "                mask = self.mask_mode\n",
    "            else:\n",
    "                mask = 'all_true'\n",
    "        \n",
    "        if mask == 'binomial':\n",
    "            mask = generate_binomial_mask(x.size(0), x.size(1)).to(x.device)\n",
    "        elif mask == 'continuous':\n",
    "            mask = generate_continuous_mask(x.size(0), x.size(1)).to(x.device)\n",
    "        elif mask == 'all_true':\n",
    "            mask = x.new_full((x.size(0), x.size(1)), True, dtype=torch.bool)\n",
    "        elif mask == 'all_false':\n",
    "            mask = x.new_full((x.size(0), x.size(1)), False, dtype=torch.bool)\n",
    "        elif mask == 'mask_last':\n",
    "            mask = x.new_full((x.size(0), x.size(1)), True, dtype=torch.bool)\n",
    "            mask[:, -1] = False\n",
    "        \n",
    "        # mask &= nan_mask\n",
    "        x[~mask] = 0\n",
    "        \n",
    "        # conv encoder\n",
    "        x = x.transpose(1, 2)  # B x Ch x T\n",
    "        x = self.repr_dropout(self.feature_extractor(x))  # B x Co x T\n",
    "        x = x.transpose(1, 2)  # B x T x Co\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def encode(self, x: PaddedBatch):\n",
    "        return self.trx_encoder(x).payload\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "# from models import TSEncoder\n",
    "from models.losses import hierarchical_contrastive_loss\n",
    "from utils import take_per_row, split_with_nan, centerize_vary_length_series, torch_pad_nan\n",
    "import math\n",
    "\n",
    "class TS2Vec:\n",
    "    '''The TS2Vec model'''\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        trx_encoder,\n",
    "        output_dims=320,\n",
    "        depth=10,\n",
    "        device='cuda',\n",
    "        lr=0.001,\n",
    "        batch_size=16,\n",
    "        max_train_length=None,\n",
    "        temporal_unit=0,\n",
    "        after_iter_callback=None,\n",
    "        after_epoch_callback=None\n",
    "    ):\n",
    "        ''' Initialize a TS2Vec model.\n",
    "        \n",
    "        Args:\n",
    "            input_dims (int): The input dimension. For a univariate time series, this should be set to 1.\n",
    "            output_dims (int): The representation dimension.\n",
    "            hidden_dims (int): The hidden dimension of the encoder.\n",
    "            depth (int): The number of hidden residual blocks in the encoder.\n",
    "            device (int): The gpu used for training and inference.\n",
    "            lr (int): The learning rate.\n",
    "            batch_size (int): The batch size.\n",
    "            max_train_length (Union[int, NoneType]): The maximum allowed sequence length for training. For sequence with a length greater than <max_train_length>, it would be cropped into some sequences, each of which has a length less than <max_train_length>.\n",
    "            temporal_unit (int): The minimum unit to perform temporal contrast. When training on a very long sequence, this param helps to reduce the cost of time and memory.\n",
    "            after_iter_callback (Union[Callable, NoneType]): A callback function that would be called after each iteration.\n",
    "            after_epoch_callback (Union[Callable, NoneType]): A callback function that would be called after each epoch.\n",
    "        '''\n",
    "        \n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.max_train_length = max_train_length\n",
    "        self.temporal_unit = temporal_unit\n",
    "        \n",
    "        self._net = TSEncoder(trx_encoder=trx_encoder, output_dims=output_dims, depth=depth).to(self.device)\n",
    "        self.net = torch.optim.swa_utils.AveragedModel(self._net)\n",
    "        self.net.update_parameters(self._net)\n",
    "        \n",
    "        self.after_iter_callback = after_iter_callback\n",
    "        self.after_epoch_callback = after_epoch_callback\n",
    "        \n",
    "        self.n_epochs = 0\n",
    "        self.n_iters = 0\n",
    "    \n",
    "    def fit(self, train_dataset, n_epochs=None, n_iters=None, verbose=False):\n",
    "        ''' Training the TS2Vec model.\n",
    "        \n",
    "        Args:\n",
    "            train_data (numpy.ndarray): The training data. It should have a shape of (n_instance, n_timestamps, n_features). All missing data should be set to NaN.\n",
    "            n_epochs (Union[int, NoneType]): The number of epochs. When this reaches, the training stops.\n",
    "            n_iters (Union[int, NoneType]): The number of iterations. When this reaches, the training stops. If both n_epochs and n_iters are not specified, a default setting would be used that sets n_iters to 200 for a dataset with size <= 100000, 600 otherwise.\n",
    "            verbose (bool): Whether to print the training loss after each epoch.\n",
    "            \n",
    "        Returns:\n",
    "            loss_log: a list containing the training losses on each epoch.\n",
    "        '''\n",
    "        # assert train_data.ndim == 3\n",
    "        \n",
    "        # if n_iters is None and n_epochs is None:\n",
    "        #     n_iters = 200 if train_data.size <= 100000 else 600  # default param for n_iters\n",
    "        \n",
    "        # if self.max_train_length is not None:\n",
    "        #     sections = train_data.shape[1] // self.max_train_length\n",
    "        #     if sections >= 2:\n",
    "        #         train_data = np.concatenate(split_with_nan(train_data, sections, axis=1), axis=0)\n",
    "\n",
    "        # temporal_missing = np.isnan(train_data).all(axis=-1).any(axis=0)\n",
    "        # if temporal_missing[0] or temporal_missing[-1]:\n",
    "        #     train_data = centerize_vary_length_series(train_data)\n",
    "                \n",
    "        # train_data = train_data[~np.isnan(train_data).all(axis=2).all(axis=1)]\n",
    "        \n",
    "        # train_dataset = TensorDataset(torch.from_numpy(train_data).to(torch.float))\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=min(self.batch_size, len(train_dataset)), \n",
    "            shuffle=True, \n",
    "            drop_last=True,\n",
    "            collate_fn=collate_feature_dict\n",
    "        )\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self._net.parameters(), lr=self.lr)\n",
    "        \n",
    "        loss_log = []\n",
    "        \n",
    "        while True:\n",
    "            if n_epochs is not None and self.n_epochs >= n_epochs:\n",
    "                break\n",
    "            \n",
    "            cum_loss = 0\n",
    "            n_epoch_iters = 0\n",
    "            \n",
    "            interrupted = False\n",
    "            for batch in train_loader:\n",
    "                if n_iters is not None and self.n_iters >= n_iters:\n",
    "                    interrupted = True\n",
    "                    break\n",
    "                \n",
    "                x = self._net.encode(batch.to(self.device))\n",
    "                if self.max_train_length is not None and x.size(1) > self.max_train_length:\n",
    "                    window_offset = np.random.randint(x.size(1) - self.max_train_length + 1)\n",
    "                    x = x[:, window_offset : window_offset + self.max_train_length]\n",
    "                # x = x.to(self.device)\n",
    "                \n",
    "                ts_l = x.size(1)\n",
    "                crop_l = np.random.randint(low=2 ** (self.temporal_unit + 1), high=ts_l+1)\n",
    "                crop_left = np.random.randint(ts_l - crop_l + 1)\n",
    "                crop_right = crop_left + crop_l\n",
    "                crop_eleft = np.random.randint(crop_left + 1)\n",
    "                crop_eright = np.random.randint(low=crop_right, high=ts_l + 1)\n",
    "                crop_offset = np.random.randint(low=-crop_eleft, high=ts_l - crop_eright + 1, size=x.size(0))\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                out1 = self._net(take_per_row(x, crop_offset + crop_eleft, crop_right - crop_eleft))\n",
    "                out1 = out1[:, -crop_l:]\n",
    "                \n",
    "                out2 = self._net(take_per_row(x, crop_offset + crop_left, crop_eright - crop_left))\n",
    "                out2 = out2[:, :crop_l]\n",
    "                \n",
    "                loss = hierarchical_contrastive_loss(\n",
    "                    out1,\n",
    "                    out2,\n",
    "                    temporal_unit=self.temporal_unit\n",
    "                )\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                self.net.update_parameters(self._net)\n",
    "                    \n",
    "                cum_loss += loss.item()\n",
    "                n_epoch_iters += 1\n",
    "                \n",
    "                self.n_iters += 1\n",
    "                \n",
    "                if self.after_iter_callback is not None:\n",
    "                    self.after_iter_callback(self, loss.item())\n",
    "            \n",
    "            if interrupted:\n",
    "                break\n",
    "            \n",
    "            cum_loss /= n_epoch_iters\n",
    "            loss_log.append(cum_loss)\n",
    "            if verbose:\n",
    "                print(f\"Epoch #{self.n_epochs}: loss={cum_loss}\")\n",
    "            self.n_epochs += 1\n",
    "            \n",
    "            if self.after_epoch_callback is not None:\n",
    "                self.after_epoch_callback(self, cum_loss)\n",
    "            \n",
    "        return loss_log\n",
    "    \n",
    "    def _eval_with_pooling(self, x, mask=None, slicing=None, encoding_window=None):\n",
    "        out = self.net(x.to(self.device, non_blocking=True), mask)\n",
    "        if encoding_window == 'full_series':\n",
    "            if slicing is not None:\n",
    "                out = out[:, slicing]\n",
    "            out = F.max_pool1d(\n",
    "                out.transpose(1, 2),\n",
    "                kernel_size = out.size(1),\n",
    "            ).transpose(1, 2)\n",
    "            \n",
    "        elif isinstance(encoding_window, int):\n",
    "            out = F.max_pool1d(\n",
    "                out.transpose(1, 2),\n",
    "                kernel_size = encoding_window,\n",
    "                stride = 1,\n",
    "                padding = encoding_window // 2\n",
    "            ).transpose(1, 2)\n",
    "            if encoding_window % 2 == 0:\n",
    "                out = out[:, :-1]\n",
    "            if slicing is not None:\n",
    "                out = out[:, slicing]\n",
    "            \n",
    "        elif encoding_window == 'multiscale':\n",
    "            p = 0\n",
    "            reprs = []\n",
    "            while (1 << p) + 1 < out.size(1):\n",
    "                t_out = F.max_pool1d(\n",
    "                    out.transpose(1, 2),\n",
    "                    kernel_size = (1 << (p + 1)) + 1,\n",
    "                    stride = 1,\n",
    "                    padding = 1 << p\n",
    "                ).transpose(1, 2)\n",
    "                if slicing is not None:\n",
    "                    t_out = t_out[:, slicing]\n",
    "                reprs.append(t_out)\n",
    "                p += 1\n",
    "            out = torch.cat(reprs, dim=-1)\n",
    "            \n",
    "        else:\n",
    "            if slicing is not None:\n",
    "                out = out[:, slicing]\n",
    "            \n",
    "        return out.cpu()\n",
    "    \n",
    "    def encode(self, data, mask=None, encoding_window=None, causal=False, sliding_length=None, sliding_padding=0, batch_size=None):\n",
    "        ''' Compute representations using the model.\n",
    "        \n",
    "        Args:\n",
    "            data (numpy.ndarray): This should have a shape of (n_instance, n_timestamps, n_features). All missing data should be set to NaN.\n",
    "            mask (str): The mask used by encoder can be specified with this parameter. This can be set to 'binomial', 'continuous', 'all_true', 'all_false' or 'mask_last'.\n",
    "            encoding_window (Union[str, int]): When this param is specified, the computed representation would the max pooling over this window. This can be set to 'full_series', 'multiscale' or an integer specifying the pooling kernel size.\n",
    "            causal (bool): When this param is set to True, the future informations would not be encoded into representation of each timestamp.\n",
    "            sliding_length (Union[int, NoneType]): The length of sliding window. When this param is specified, a sliding inference would be applied on the time series.\n",
    "            sliding_padding (int): This param specifies the contextual data length used for inference every sliding windows.\n",
    "            batch_size (Union[int, NoneType]): The batch size used for inference. If not specified, this would be the same batch size as training.\n",
    "            \n",
    "        Returns:\n",
    "            repr: The representations for data.\n",
    "        '''\n",
    "        assert self.net is not None, 'please train or load a net first'\n",
    "        assert data.ndim == 3\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        n_samples, ts_l, _ = data.shape\n",
    "\n",
    "        org_training = self.net.training\n",
    "        self.net.eval()\n",
    "        \n",
    "        dataset = TensorDataset(torch.from_numpy(data).to(torch.float))\n",
    "        loader = DataLoader(dataset, batch_size=batch_size)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = []\n",
    "            for batch in loader:\n",
    "                x = batch[0]\n",
    "                if sliding_length is not None:\n",
    "                    reprs = []\n",
    "                    if n_samples < batch_size:\n",
    "                        calc_buffer = []\n",
    "                        calc_buffer_l = 0\n",
    "                    for i in range(0, ts_l, sliding_length):\n",
    "                        l = i - sliding_padding\n",
    "                        r = i + sliding_length + (sliding_padding if not causal else 0)\n",
    "                        x_sliding = torch_pad_nan(\n",
    "                            x[:, max(l, 0) : min(r, ts_l)],\n",
    "                            left=-l if l<0 else 0,\n",
    "                            right=r-ts_l if r>ts_l else 0,\n",
    "                            dim=1\n",
    "                        )\n",
    "                        if n_samples < batch_size:\n",
    "                            if calc_buffer_l + n_samples > batch_size:\n",
    "                                out = self._eval_with_pooling(\n",
    "                                    torch.cat(calc_buffer, dim=0),\n",
    "                                    mask,\n",
    "                                    slicing=slice(sliding_padding, sliding_padding+sliding_length),\n",
    "                                    encoding_window=encoding_window\n",
    "                                )\n",
    "                                reprs += torch.split(out, n_samples)\n",
    "                                calc_buffer = []\n",
    "                                calc_buffer_l = 0\n",
    "                            calc_buffer.append(x_sliding)\n",
    "                            calc_buffer_l += n_samples\n",
    "                        else:\n",
    "                            out = self._eval_with_pooling(\n",
    "                                x_sliding,\n",
    "                                mask,\n",
    "                                slicing=slice(sliding_padding, sliding_padding+sliding_length),\n",
    "                                encoding_window=encoding_window\n",
    "                            )\n",
    "                            reprs.append(out)\n",
    "\n",
    "                    if n_samples < batch_size:\n",
    "                        if calc_buffer_l > 0:\n",
    "                            out = self._eval_with_pooling(\n",
    "                                torch.cat(calc_buffer, dim=0),\n",
    "                                mask,\n",
    "                                slicing=slice(sliding_padding, sliding_padding+sliding_length),\n",
    "                                encoding_window=encoding_window\n",
    "                            )\n",
    "                            reprs += torch.split(out, n_samples)\n",
    "                            calc_buffer = []\n",
    "                            calc_buffer_l = 0\n",
    "                    \n",
    "                    out = torch.cat(reprs, dim=1)\n",
    "                    if encoding_window == 'full_series':\n",
    "                        out = F.max_pool1d(\n",
    "                            out.transpose(1, 2).contiguous(),\n",
    "                            kernel_size = out.size(1),\n",
    "                        ).squeeze(1)\n",
    "                else:\n",
    "                    out = self._eval_with_pooling(x, mask, encoding_window=encoding_window)\n",
    "                    if encoding_window == 'full_series':\n",
    "                        out = out.squeeze(1)\n",
    "                        \n",
    "                output.append(out)\n",
    "                \n",
    "            output = torch.cat(output, dim=0)\n",
    "            \n",
    "        self.net.train(org_training)\n",
    "        return output.numpy()\n",
    "    \n",
    "    def save(self, fn):\n",
    "        ''' Save the model to a file.\n",
    "        \n",
    "        Args:\n",
    "            fn (str): filename.\n",
    "        '''\n",
    "        torch.save(self.net.state_dict(), fn)\n",
    "    \n",
    "    def load(self, fn):\n",
    "        ''' Load the model from a file.\n",
    "        \n",
    "        Args:\n",
    "            fn (str): filename.\n",
    "        '''\n",
    "        state_dict = torch.load(fn, map_location=self.device)\n",
    "        self.net.load_state_dict(state_dict)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TS2Vec(trx_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0: loss=4.249246235318512\n",
      "Epoch #1: loss=2.406607280858615\n",
      "Epoch #2: loss=2.202019851217386\n",
      "Epoch #3: loss=2.044677399913309\n",
      "Epoch #4: loss=1.998812815438398\n",
      "Epoch #5: loss=2.014667148049544\n",
      "Epoch #6: loss=1.904794717607228\n",
      "Epoch #7: loss=1.8790204896617997\n",
      "Epoch #8: loss=1.8386888122751646\n",
      "Epoch #9: loss=1.803795264800068\n",
      "Epoch #10: loss=1.7997330808446474\n",
      "Epoch #11: loss=1.7175399115693715\n",
      "Epoch #12: loss=1.7735411051796515\n",
      "Epoch #13: loss=1.7911778900787416\n",
      "Epoch #14: loss=1.6982846778896656\n",
      "Epoch #15: loss=1.6533252900911246\n",
      "Epoch #16: loss=1.6572428410835112\n",
      "Epoch #17: loss=1.6336104874668815\n",
      "Epoch #18: loss=1.67700676686368\n",
      "Epoch #19: loss=1.7107238972235306\n",
      "Epoch #20: loss=1.6551401248345008\n",
      "Epoch #21: loss=1.6803750366817118\n",
      "Epoch #22: loss=1.6315721992539007\n",
      "Epoch #23: loss=1.549530402851491\n",
      "Epoch #24: loss=1.618836478183144\n",
      "Epoch #25: loss=1.6149939054902267\n",
      "Epoch #26: loss=1.612598803120586\n",
      "Epoch #27: loss=1.6124785559380104\n",
      "Epoch #28: loss=1.6927147999948817\n",
      "Epoch #29: loss=1.635016747814441\n",
      "Epoch #30: loss=1.618752583559708\n",
      "Epoch #31: loss=1.529177398334148\n",
      "Epoch #32: loss=1.5926515028061654\n",
      "Epoch #33: loss=1.5699852548147504\n",
      "Epoch #34: loss=1.5325368843097917\n",
      "Epoch #35: loss=1.531386982574154\n",
      "Epoch #36: loss=1.4648267679851548\n",
      "Epoch #37: loss=1.610720699615324\n",
      "Epoch #38: loss=1.483416305379829\n",
      "Epoch #39: loss=1.5171632042780578\n",
      "Epoch #40: loss=1.516376354433747\n",
      "Epoch #41: loss=1.5805620973409429\n",
      "Epoch #42: loss=1.4937670189842038\n",
      "Epoch #43: loss=1.5951656214138756\n",
      "Epoch #44: loss=1.552167242837821\n",
      "Epoch #45: loss=1.5102267224296384\n",
      "Epoch #46: loss=1.581756353378296\n",
      "Epoch #47: loss=1.5502005936163157\n",
      "Epoch #48: loss=1.590456288594466\n",
      "Epoch #49: loss=1.540316305421142\n",
      "Epoch #50: loss=1.5570553447070874\n",
      "Epoch #51: loss=1.4240310287427322\n",
      "Epoch #52: loss=1.5286501583300138\n",
      "Epoch #53: loss=1.4807373586936519\n",
      "Epoch #54: loss=1.460384657146477\n",
      "Epoch #55: loss=1.5045573315639726\n",
      "Epoch #56: loss=1.5192873646855838\n",
      "Epoch #57: loss=1.5132831573968957\n",
      "Epoch #58: loss=1.4556976646064264\n",
      "Epoch #59: loss=1.4585221622154299\n"
     ]
    }
   ],
   "source": [
    "loss_log = model.fit(train, 60, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.net.state_dict(), \"averaged_model_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model._net.state_dict(), \"model_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20ce6fc96a0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_data(data, model):\n",
    "    embeddings, targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq in data:\n",
    "            x = collate_feature_dict([seq]).to(model.device)\n",
    "            emb = model._net.encode(x)\n",
    "            out = model._net(emb)\n",
    "            seq_emb = out.max(dim=1).values.squeeze().cpu().numpy()\n",
    "            embeddings.append(seq_emb)\n",
    "            targets.append(seq[\"global_target\"])\n",
    "\n",
    "    return np.array(embeddings), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = embed_data(train, model)\n",
    "X_test, y_test = embed_data(test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7264959050643491"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# logreg = LogisticRegression(max_iter=1000)\n",
    "# logreg.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=500, verbose=-1)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgbm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTLS models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TS2VecDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        feature_arrays = self.data[item]\n",
    "        return feature_arrays\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        return collate_feature_dict(batch), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def hierarchical_contrastive_loss(z1, z2, alpha=0.5, temporal_unit=0):\n",
    "    loss = torch.tensor(0., device=z1.device)\n",
    "    d = 0\n",
    "    while z1.size(1) > 1:\n",
    "        if alpha != 0:\n",
    "            loss += alpha * instance_contrastive_loss(z1, z2)\n",
    "        if d >= temporal_unit:\n",
    "            if 1 - alpha != 0:\n",
    "                loss += (1 - alpha) * temporal_contrastive_loss(z1, z2)\n",
    "        d += 1\n",
    "        z1 = F.max_pool1d(z1.transpose(1, 2), kernel_size=2).transpose(1, 2)\n",
    "        z2 = F.max_pool1d(z2.transpose(1, 2), kernel_size=2).transpose(1, 2)\n",
    "    if z1.size(1) == 1:\n",
    "        if alpha != 0:\n",
    "            loss += alpha * instance_contrastive_loss(z1, z2)\n",
    "        d += 1\n",
    "    return loss / d\n",
    "\n",
    "\n",
    "def instance_contrastive_loss(z1, z2):\n",
    "    B, T = z1.size(0), z1.size(1)\n",
    "    if B == 1:\n",
    "        return z1.new_tensor(0.)\n",
    "    z = torch.cat([z1, z2], dim=0)  # 2B x T x C\n",
    "    z = z.transpose(0, 1)  # T x 2B x C\n",
    "    sim = torch.matmul(z, z.transpose(1, 2))  # T x 2B x 2B\n",
    "    logits = torch.tril(sim, diagonal=-1)[:, :, :-1]    # T x 2B x (2B-1)\n",
    "    logits += torch.triu(sim, diagonal=1)[:, :, 1:]\n",
    "    logits = -F.log_softmax(logits, dim=-1)\n",
    "    \n",
    "    i = torch.arange(B, device=z1.device)\n",
    "    loss = (logits[:, i, B + i - 1].mean() + logits[:, B + i, i].mean()) / 2\n",
    "    return loss\n",
    "\n",
    "\n",
    "def temporal_contrastive_loss(z1, z2):\n",
    "    B, T = z1.size(0), z1.size(1)\n",
    "    if T == 1:\n",
    "        return z1.new_tensor(0.)\n",
    "    z = torch.cat([z1, z2], dim=1)  # B x 2T x C\n",
    "    sim = torch.matmul(z, z.transpose(1, 2))  # B x 2T x 2T\n",
    "    logits = torch.tril(sim, diagonal=-1)[:, :, :-1]    # B x 2T x (2T-1)\n",
    "    logits += torch.triu(sim, diagonal=1)[:, :, 1:]\n",
    "    logits = -F.log_softmax(logits, dim=-1)\n",
    "    \n",
    "    t = torch.arange(T, device=z1.device)\n",
    "    loss = (logits[:, t, T + t - 1].mean() + logits[:, T + t, t].mean()) / 2\n",
    "    return loss\n",
    "\n",
    "\n",
    "def take_per_row(A, indx, num_elem):\n",
    "    all_indx = indx[:,None] + np.arange(num_elem)\n",
    "    return A[torch.arange(all_indx.shape[0])[:,None], all_indx]\n",
    "\n",
    "\n",
    "class HierarchicalContrastiveLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, temporal_unit=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.temporal_unit = temporal_unit\n",
    "\n",
    "    def forward(self, embeddings, _):\n",
    "        out1, out2 = embeddings\n",
    "        return hierarchical_contrastive_loss(out1, out2, self.alpha, self.temporal_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.frames.abs_module import ABSModule\n",
    "from torchmetrics import MeanMetric\n",
    "\n",
    "\n",
    "class TS2Vec(ABSModule):\n",
    "    '''The TS2Vec model'''\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_encoder,\n",
    "        loss=None,\n",
    "        validation_metric=None,\n",
    "        optimizer_partial=None,\n",
    "        lr_scheduler_partial=None\n",
    "    ):\n",
    "        ''' Initialize a TS2Vec model.\n",
    "        \n",
    "        Args:\n",
    "        '''\n",
    "        \n",
    "        if loss is None:\n",
    "            loss = HierarchicalContrastiveLoss(alpha=0.5, temporal_unit=0)\n",
    "\n",
    "        self.temporal_unit = loss.temporal_unit\n",
    "        \n",
    "        # if validation_metric is None:\n",
    "\n",
    "        super().__init__(validation_metric,\n",
    "                         seq_encoder,\n",
    "                         loss,\n",
    "                         optimizer_partial,\n",
    "                         lr_scheduler_partial)\n",
    "\n",
    "        self.valid_loss = MeanMetric()\n",
    "\n",
    "    def shared_step(self, x, y):\n",
    "        trx_encoder = self._seq_encoder.trx_encoder\n",
    "        seq_encoder = self._seq_encoder.seq_encoder \n",
    "\n",
    "        seq_lens = x.seq_lens\n",
    "        x = trx_encoder(x).payload\n",
    "\n",
    "        ts_l = x.size(1)\n",
    "        crop_l = np.random.randint(low=2 ** (self.temporal_unit + 1), high=ts_l+1)\n",
    "        crop_left = np.random.randint(ts_l - crop_l + 1)\n",
    "        crop_right = crop_left + crop_l\n",
    "        crop_eleft = np.random.randint(crop_left + 1)\n",
    "        crop_eright = np.random.randint(low=crop_right, high=ts_l + 1)\n",
    "        crop_offset = np.random.randint(low=-crop_eleft, high=ts_l - crop_eright + 1, size=x.size(0))\n",
    "\n",
    "        input1 = PaddedBatch(take_per_row(x, crop_offset + crop_eleft, crop_right - crop_eleft), seq_lens)\n",
    "        input2 = PaddedBatch(take_per_row(x, crop_offset + crop_left, crop_eright - crop_left), seq_lens)\n",
    "        \n",
    "        out1 = seq_encoder(input1).payload\n",
    "        out1 = out1[:, -crop_l:]\n",
    "                \n",
    "        out2 = seq_encoder(input2).payload\n",
    "        out2 = out2[:, :crop_l]\n",
    "        \n",
    "        return (out1, out2), y\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        y_h, y = self.shared_step(*batch)\n",
    "        loss = self._loss(y_h, y)\n",
    "        self.valid_loss(loss)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        self.log(f'valid_loss', self.valid_loss, prog_bar=True)\n",
    "        # self._validation_metric.reset()\n",
    "\n",
    "    @property\n",
    "    def is_requires_reduced_sequence(self):\n",
    "        return False\n",
    "    \n",
    "    @property\n",
    "    def metric_name(self):\n",
    "        return \"valid_loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.nn.seq_encoder.containers import SeqEncoderContainer\n",
    "from ptls.nn.seq_encoder.abs_seq_encoder import AbsSeqEncoder\n",
    "from ptls.data_load.padded_batch import PaddedBatch\n",
    "from models.dilated_conv import DilatedConvEncoder\n",
    "\n",
    "\n",
    "def generate_binomial_mask(B, T, p=0.5):\n",
    "    return torch.from_numpy(np.random.binomial(1, p, size=(B, T))).to(torch.bool)\n",
    "\n",
    "\n",
    "class ConvEncoder(AbsSeqEncoder):\n",
    "    def __init__(self,\n",
    "                 input_size=None,\n",
    "                 hidden_size=None,\n",
    "                 num_layers=10,\n",
    "                 dropout=0,\n",
    "                 mask_mode='binomial',\n",
    "                 is_reduce_sequence=False,  \n",
    "                 reducer='maxpool'\n",
    "                 ):\n",
    "        \n",
    "        super().__init__(is_reduce_sequence=is_reduce_sequence)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.mask_mode = mask_mode\n",
    "\n",
    "        self.feature_extractor = DilatedConvEncoder(\n",
    "            input_size,\n",
    "            [hidden_size] * num_layers + [hidden_size],\n",
    "            kernel_size=3\n",
    "        )\n",
    "\n",
    "        self.repr_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.reducer = reducer\n",
    "\n",
    "    def forward(self, x: PaddedBatch, mask=None):  # x: B x T x input_dims\n",
    "        shape = x.payload.size()\n",
    "\n",
    "        # generate & apply mask\n",
    "        if mask is None:\n",
    "            if self.training:\n",
    "                mask = self.mask_mode\n",
    "            else:\n",
    "                mask = 'all_true'\n",
    "        \n",
    "        if mask == 'binomial':\n",
    "            mask = generate_binomial_mask(shape[0], shape[1]).to(x.device)\n",
    "        elif mask == 'continuous':\n",
    "            mask = generate_continuous_mask(shape[0], shape[1]).to(x.device)\n",
    "        elif mask == 'all_true':\n",
    "            mask = x.payload.new_full((shape[0], shape[1]), True, dtype=torch.bool)\n",
    "        elif mask == 'all_false':\n",
    "            mask = x.payload.new_full((shape[0], shape[1]), False, dtype=torch.bool)\n",
    "        elif mask == 'mask_last':\n",
    "            mask = x.payload.new_full((shape[0], shape[1]), True, dtype=torch.bool)\n",
    "            mask[:, -1] = False\n",
    "        \n",
    "        x_masked = x.payload\n",
    "        x_masked[~mask] = 0\n",
    "        \n",
    "        # conv encoder\n",
    "        x_masked = x_masked.transpose(1, 2)  # B x Ch x T\n",
    "        out = self.repr_dropout(self.feature_extractor(x_masked))  # B x Co x T\n",
    "        out = x_masked.transpose(1, 2)  # B x T x Co\n",
    "        \n",
    "        out = PaddedBatch(out, x.seq_lens)\n",
    "        if self.is_reduce_sequence:\n",
    "            out = out.payload.max(dim=1).values\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSeqEncoder(SeqEncoderContainer):\n",
    "    def __init__(self,\n",
    "                trx_encoder=None,\n",
    "                input_size=None,\n",
    "                is_reduce_sequence=False,\n",
    "                **seq_encoder_params,\n",
    "                ):\n",
    "        super().__init__(\n",
    "            trx_encoder=trx_encoder,\n",
    "            seq_encoder_cls=ConvEncoder,\n",
    "            input_size=input_size,\n",
    "            seq_encoder_params=seq_encoder_params,\n",
    "            is_reduce_sequence=is_reduce_sequence,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.frames import PtlsDataModule\n",
    "\n",
    "datamodule: PtlsDataModule = PtlsDataModule(\n",
    "    train_data=TS2VecDataset(train),\n",
    "    valid_data=TS2VecDataset(test),\n",
    "    train_batch_size=16,\n",
    "    valid_batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_encoder = ConvSeqEncoder(\n",
    "    TrxEncoder(\n",
    "        embeddings={\"mcc_code\": {\"in\": 345, \"out\": 24}},\n",
    "        numeric_values={\"amount\": \"identity\"}\n",
    "    ),  \n",
    "    **{\n",
    "        \"hidden_size\": 320,\n",
    "        \"num_layers\": 10,\n",
    "        \"dropout\": 0.1,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim import AdamW\n",
    "from ptls.frames.coles.coles_module import CoLESModule \n",
    "\n",
    "scheduler_partial = partial(ReduceLROnPlateau, factor=.9025, patience=50)\n",
    "optimizer_partial = partial(AdamW, lr=0.1, weight_decay=0.0)\n",
    "\n",
    "model = TS2Vec(seq_encoder, optimizer_partial=optimizer_partial, lr_scheduler_partial=scheduler_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type                        | Params\n",
      "-------------------------------------------------------------\n",
      "0 | _loss        | HierarchicalContrastiveLoss | 0     \n",
      "1 | _seq_encoder | ConvSeqEncoder              | 6.6 M \n",
      "2 | valid_loss   | MeanMetric                  | 0     \n",
      "-------------------------------------------------------------\n",
      "6.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 M     Total params\n",
      "26.406    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0596eb56e0e4f4cb40b31277674e66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd10693239f45169272b52e3875d57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f4f07c571a47d5ab31afedd4fcb814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d575b23e0f8445268597db8fcde9f5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbb1898da7e4c7ab09ef760e99f7bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f898d701524ce78cd142290e00ca21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbefa0dec504d4daa10ca97bd5b5bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f1015bc3264bfb8f8fd10cfae4dfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fdf0a6ec5224c358f75d63ac0bde020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45546ef164774961ae1beb8fc4ee00d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da0bdec8a084e1cb3c897c33f6c31e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040fb50410f94fa0b18ae4e211932763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5d4ab607cb45e6b0da9f42a85772f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4993308005e48e7aaa630e250e9bf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e8fb1c1c66440895a9d590d915e182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ae679db4b942399accf76413c04297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839bc7ac0a994edcbc705c8220237891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b807348252fb4c80ba2480e66422ed4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546deb4c14e24e2e84b1fd649c2c980a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e3effc09f4490697c12b7502555a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7cf2e57b514b829983b7982c68438d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e0e3468bfd4683bdc9420eec7bee43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce51a9e669f144f291befa5fe7614be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5539b2c5d4bd41c08e32ec106ac4ac6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcfa58dea645476c9ced13a6d56f493e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15da59a45f24736a8e56ce1cf780ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0568d7af89ce4aa980348ce0423e59e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d5778d3ead42cabb1e769bce7acbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7fecdfc38549c58a47cc64866a9a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da01955132464cf6b89ac05e37fd2aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96835c84534c44aa8e4fb655069730f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bade4e6dc947938a04c319d64cdb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb08613e5a314f8abfaef1dd804e20e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48673172bedd4184bc531335521d4ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b93f596aec4eeda3669a4ba7f183a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8923c97bcca74cdc94479274d53b61e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182a7f4f70d04d12841c29fc36004a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a59a503705b4b5a80f8e80537638163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8171bab0272f43c88ecb14423093a062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37162028e58e4d53afe3462525f3dcac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0523ffac00e04506ab91685ef89cab7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8af449294dd440d91076ef45e96e028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23f2f344f4942309c9dd7af9f1dd2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed174a7d9ed4a348ce56acb46891777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354ba846c0e8421bbdbbe02398d15bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8181505dbdcf4b23b924ee9fba93452d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c842d9851340dd848f1a55d7e96b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42949e554efd4a1d983a149ed3434097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219cb7dd19814761adf76c8d42b43c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9594980ac423458e8c25248005ec8cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72c583c74d4414780114bd6086bcf25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96cc41de89c4232ad73bd6ba24eefaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_data(data, model):\n",
    "    embeddings, targets = [], []\n",
    "\n",
    "    model.eval()\n",
    "    model.training = False\n",
    "    model.seq_encoder.is_reduce_sequence = True \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq in data:\n",
    "            x = collate_feature_dict([seq]).to(model.device)\n",
    "            seq_emb = model(x).squeeze().cpu().numpy()\n",
    "            embeddings.append(seq_emb)\n",
    "            targets.append(seq[\"global_target\"])\n",
    "\n",
    "    return np.array(embeddings), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = embed_data(train, model)\n",
    "X_test, y_test = embed_data(test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6689665484684069"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# lgbm = LGBMClassifier(n_estimators=500, verbose=-1)\n",
    "# lgbm.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = lgbm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
